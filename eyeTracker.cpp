#include "eyeTracker.h"

void EyeTracker::detectFace(cv::Mat& cameraFrame){
    /* Local Variables */
    cv::Mat grayscale;
    std::vector<cv::Rect> faceLikes;
    cv::Rect faceROI;
    uint16_t faceROIErrorCount = 0;

    // 1. Preprocess the cameraFrame Mat.
    cv::flip(cameraFrame, cameraFrame, 1);
    cv::cvtColor(cameraFrame, grayscale, cv::COLOR_BGR2GRAY);

    // 2. Detect Face-like areas.
    this->faceClassifier.detectMultiScale(grayscale, faceLikes, 1.1, ET__CASCADE_FACE_MIN_NEIGHBORS);

    // 3. Select Most Face-like area to Face.
    if(faceLikes.size()==1){ 
        // Just one face has detected.
        faceROI = faceLikes.at(0);

        // Check face ROI is valid area.
        if(this->getFaceROIBuffer().empty()){
            this->pushToFaceROIBuffer(faceROI);
        }else{
            if(this->getFaceROIBuffer().size() >= ET__MAX_BUFFER_LENGTH){
                this->popFromFaceROIBuffer();
            }

            if( abs(this->getLastFaceROI().x - faceROI.x) > ET__CASCADE_FACE_MARGIN_PIXEL || 
                abs(this->getLastFaceROI().y - faceROI.y) > ET__CASCADE_FACE_MARGIN_PIXEL ){
                    // Replace Argorithm
                    std::vector<cv::Rect> faceROIAreas;
                    std::vector<int> faceROICounts;
                    int faceLikesNum = 0;

                    for(cv::Rect faceROIFromBuffer : this->getFaceROIBuffer()){
                        if(faceROIAreas.empty()){
                            faceROIAreas.push_back(faceROIFromBuffer);
                            faceROICounts.push_back(1);
                            faceLikesNum++;
                        }else{
                            int cnt = 0;
                            for(cv::Rect faceROIArea : faceROIAreas){
                                if( abs(faceROIArea.x - faceROIFromBuffer.x) > ET__CASCADE_FACE_MARGIN_PIXEL ||
                                    abs(faceROIArea.y - faceROIFromBuffer.y) > ET__CASCADE_FACE_MARGIN_PIXEL){

                                    faceROIAreas.push_back(faceROIFromBuffer);
                                    faceROICounts.push_back(1);
                                    faceLikesNum++;
                                }else{
                                    faceROIAreas.at(cnt) = faceROIFromBuffer; // Update for restore last position of faceROI. 
                                    faceROICounts.at(cnt)++;
                                }
                                cnt++;
                            }
                        }
                    }

                    int maxNum = 0;
                    for(int i = 0; i < faceROIAreas.size(); i++){
                        if(faceROICounts.at(i) > maxNum){
                            maxNum = faceROICounts.at(i);
                            faceROI = faceROIAreas.at(i);
                        }
                    }
            }

            this->pushToFaceROIBuffer(faceROI);
        }

    }else{ 
        // Multiple face-like areas have detected.
        if(faceROIErrorCount < ET__MAX_ERROR_COUNT){ 
            // The time yet in error margin.
            faceROI = this->getLastFaceROI();
            faceROIErrorCount++;
        }else{
            // The time is out of error margin.
            this->resetFaceROIBuffer();
            faceROI = cv::Rect();
            faceROIErrorCount = 0;
        }
    }

    // 4. Restore last face Region-Of-Interest.
    this->setLastFaceROI(faceROI);
}

// [ NOTICE ]
// Left and Right Eye ROI Rect is independent from faceROI. 
// They have to add faceROI.tl() and faceROI.width/2(especially RightEyeROI) when they used.
void EyeTracker::detectEyesUsingHaar(cv::Mat& cameraFrame){
    // Add
    this->detectFace(cameraFrame);
    
    /* Local Variables */
    uint16_t leftEyeROIErrorCount = 0;
    uint16_t rightEyeROIErrorCount = 0;
    cv::Rect faceROI = this->getLastFaceROI();
    cv::Point faceROILoc = cv::Point(faceROI.x, faceROI.y);
    uint16_t faceROIWidth = cvRound(faceROI.width);
    uint16_t faceROIHeight = cvRound(faceROI.height);
    std::vector<cv::Rect> leftEyeLikes, rightEyeLikes;
    cv::Rect leftEyeROI, rightEyeROI;
    cv::Point leftEyeLoc, rightEyeLoc;

    // 1. Select areas that each eye can exist.
    cv::Rect leftEyeArea(faceROILoc.x,                  faceROILoc.y, faceROIWidth/2, faceROIHeight);
    cv::Rect rightEyeArea(faceROILoc.x+faceROIWidth/2,  faceROILoc.y, faceROIWidth/2, faceROIHeight);

    // 2. Detect eye-like areas for each Rect.
    this->eyeClassifier.detectMultiScale(cameraFrame(leftEyeArea), leftEyeLikes, 1.1, ET__CASCADE_EYE_MIN_NEIGHBORS);
    this->eyeClassifier.detectMultiScale(cameraFrame(rightEyeArea), rightEyeLikes, 1.1, ET__CASCADE_EYE_MIN_NEIGHBORS);

    // 3. Select most eye-like area to each eye.
    //// (1)Left
    if(leftEyeLikes.size()==1){
        // Just one leftEye has detected.
        leftEyeROI = leftEyeLikes.at(0);
        if(this->getLeftEyeROIBuffer().size() > ET__MAX_BUFFER_LENGTH){
            this->popFromLeftEyeROIBuffer();
        }
        this->pushToLeftEyeROIBuffer(leftEyeROI);
    }else if(leftEyeLikes.empty()){
        // None leftEye has detected.(Probably this mainly meaning of blink.)
        
        // leftEyeROI = this->getLastLeftEyeROI();
        leftEyeROI = cv::Rect();
    }else{
        // Multiple leftEye-like areas have detected.
        if(leftEyeROIErrorCount < ET__MAX_ERROR_COUNT){ 
            // The time yet in error margin.
            if(this->getLeftEyeROIBuffer().size() > 1){
                leftEyeROI = this->getLastLeftEyeROI();
                leftEyeROIErrorCount++;
            }else{
                leftEyeROI = cv::Rect();
            }
        }else{
            // The time is out of error margin.
            this->resetLeftEyeROIBuffer();
            leftEyeROI = cv::Rect();
            leftEyeROIErrorCount = 0;
        }
    }
    //// (2)Right
    if(rightEyeLikes.size()==1){
        // Just one rightEye has detected.
        rightEyeROI = rightEyeLikes.at(0);
        if(this->getRightEyeROIBuffer().size() > ET__MAX_BUFFER_LENGTH){
            this->popFromRightEyeROIBuffer();
        }
        this->pushToRightEyeROIBuffer(rightEyeROI);
    }else if(rightEyeLikes.empty()){
        // None rightEye has detected.(Probably this mainly meaning of blink.)

        // rightEyeROI = this->getLastRightEyeROI();
        rightEyeROI = cv::Rect();
    }else{
        // Multiple rightEye-like areas have detected.
        if(rightEyeROIErrorCount < ET__MAX_ERROR_COUNT){ 
            // The time yet in error margin.
            if(this->getRightEyeROIBuffer().size() > 1){
                rightEyeROI = this->getLastRightEyeROI();
                rightEyeROIErrorCount++;
            }else{
                rightEyeROI = cv::Rect();
            }
        }else{
            // The time is out of error margin.
            this->resetRightEyeROIBuffer();
            rightEyeROI = cv::Rect();
            rightEyeROIErrorCount = 0;
        }
    }

    // 4. Restore location, Region-Of-Interest area, center point of each eye.
    this->setLastLeftEyeROI(leftEyeROI);
    this->setLastRightEyeROI(rightEyeROI);
    this->setLastLeftEyeCenter(
        cv::Point(
            cvRound(leftEyeROI.x + leftEyeROI.width/2), 
            cvRound(leftEyeROI.y + leftEyeROI.height/2)
        )
    );
    this->setLastRightEyeCenter(
        cv::Point(
            cvRound(rightEyeROI.x + rightEyeROI.width/2),
            cvRound(rightEyeROI.y + rightEyeROI.height/2)
        )
    );
}

void EyeTracker::adjustEyes2Face(cv::Rect& faceROI, cv::Rect& leftEyeROI, cv::Rect& rightEyeROI, cv::Point& leftEyeCenter, cv::Point& rightEyeCenter){
    leftEyeROI = cv::Rect(
        cv::Point(faceROI.tl() + leftEyeROI.tl()),
        leftEyeROI.size()
    );
    rightEyeROI = cv::Rect(
        cv::Point(faceROI.tl() + rightEyeROI.tl() + cv::Point(faceROI.width/2, 0)),
        rightEyeROI.size()
    );
    leftEyeCenter = cv::Point(
        faceROI.x + leftEyeCenter.x,
        faceROI.y + leftEyeCenter.y
    );
    rightEyeCenter = cv::Point(
        faceROI.x + rightEyeCenter.x + faceROI.width/2,
        faceROI.y + rightEyeCenter.y
    );
}

/* Detect Eyes Using EyePicker Algorithm. */
void EyeTracker::detectEyesUsingEyePicker(cv::Mat& cameraFrame){
    detectionData output;
    cv::Rect faceROI;
    cv::Mat grayFrame;

    this->detectFace(cameraFrame);
    faceROI = this->getLastFaceROI();
    cv::cvtColor(cameraFrame, grayFrame, cv::COLOR_BGR2GRAY);
    this->selectEyeArea(grayFrame, faceROI, output);
    
    // Restore adjusted data.
    switch(output.eyeState){
        case EP__EYE_STATE_OPEN:
            this->setLastLeftEyeROI(cv::Rect(cv::Point(output.leftEyeRegion.tl() + faceROI.tl()), cv::Size(output.leftEyeRegion.size())));
            this->setLastRightEyeROI(cv::Rect(cv::Point(output.rightEyeRegion.tl() + faceROI.tl()), cv::Size(output.rightEyeRegion.size())));
            this->setLastLeftEyeCenter(faceROI.tl() + output.leftEyePosition);
            this->setLastRightEyeCenter(faceROI.tl() + output.rightEyePosition);
            break;

        case EP__EYE_STATE_CLOSE:
            this->outputData.leftEyeRegion = cv::Rect();
            this->outputData.rightEyeRegion = cv::Rect();
            this->outputData.leftEyePosition = cv::Point();
            this->outputData.rightEyePosition = cv::Point();
            this->outputData.resultleftEyePosition = cv::Point();
            this->outputData.resultrightEyePosition = cv::Point();
            
            this->setLastLeftEyeROI(cv::Rect());
            this->setLastRightEyeROI(cv::Rect());
            this->setLastLeftEyeCenter(cv::Point());
            this->setLastRightEyeCenter(cv::Point());
            break;

        case EP__EYE_STATE_LEFT_CLOSED:
            this->outputData.leftEyeRegion = cv::Rect();
            this->outputData.leftEyePosition = cv::Point();
            this->outputData.resultleftEyePosition = cv::Point();

            this->setLastLeftEyeROI(cv::Rect());
            this->setLastRightEyeROI(cv::Rect(cv::Point(output.rightEyeRegion.tl() + faceROI.tl()), cv::Size(output.rightEyeRegion.size())));
            this->setLastLeftEyeCenter(cv::Point());
            this->setLastRightEyeCenter(faceROI.tl() + output.rightEyePosition);
            break;

        case EP__EYE_STATE_RIGHT_CLOSED:
            this->outputData.rightEyeRegion = cv::Rect();
            this->outputData.rightEyePosition = cv::Point();
            this->outputData.resultrightEyePosition = cv::Point();

            this->setLastLeftEyeROI(cv::Rect(cv::Point(output.leftEyeRegion.tl() + faceROI.tl()), cv::Size(output.leftEyeRegion.size())));
            this->setLastRightEyeROI(cv::Rect());
            this->setLastLeftEyeCenter(faceROI.tl() + output.leftEyePosition);
            this->setLastRightEyeCenter(cv::Point());
            break;
        default:
            break;
    }
}

/* MAIN ALGORITHM */
// TODO: ì¸í„°í˜ì´ìŠ¤ í† ê¸€ì— ë”°ë¼ í™œì„± ë¹„í™œì„± ë™ì‘ ì¶”ê°€í•´ì•¼í•¨!!
// TODO: ì¸ì‹ë¥ ì„ ìœ„í•´ ë²„í¼ ë‚´ì˜ ê°’ë“¤ì— ëŒ€í•œ ì˜¤ë¥˜ ë§ˆì§„ì„ ë‘ëŠ” ë°©í–¥ìœ¼ë¡œ ìˆ˜ì •í•´ì•¼í•¨!!
// TODO: ì»¤ì„œ ì´ë™ í‘œí˜„
// TODO: ìš°í´ë¦­ ì•ˆë¨ ìˆ˜ì •
Gesture EyeTracker::traceAndTranslate2Gesture(cv::Mat& cameraFrame){
    /* Variables */
    cv::Rect faceROI, leftEyeROI, rightEyeROI;
    cv::Point leftEyeCenter, rightEyeCenter;

    std::chrono::duration<double> totalTime, accumulatedTime, detectionTime, durationTime;
    std::chrono::microseconds totalTimeMS;
    std::chrono::system_clock::time_point start;

    bool isLeftEyeOpen = true; 
    bool isRightEyeOpen = true;

    GestureData lastGestureData, thisGestureData;

    Gesture result;


    // Start Point Of Duration.
    start = std::chrono::system_clock::now();

    // 1. Detect face and eyes. (per single frame)
    // this->detectEyesUsingHaar(cameraFrame);
    this->detectEyesUsingEyePicker(cameraFrame);

    // 2. Adjusting both eyes' information.
    faceROI = this->getLastFaceROI();
    leftEyeROI = this->getLastLeftEyeROI();
    rightEyeROI = this->getLastRightEyeROI();
    leftEyeCenter = this->getLastLeftEyeCenter();
    rightEyeCenter = this->getLastRightEyeCenter();
    // If you use detectEyesUsingHaar, than you have to run adjustEyes2Face code below.
    //// this->adjustEyes2Face(faceROI, leftEyeROI, rightEyeROI, leftEyeCenter, rightEyeCenter); // Use only with detectEyesUsingHaar()

    // 3. Translate to Gesture. 
    //// 1) Check eyes are opened.
    if(leftEyeROI.empty()){ isLeftEyeOpen = false; }
    if(rightEyeROI.empty()){ isRightEyeOpen = false; }  

    //// 2) Translate to gesture.
    lastGestureData = this->getLastGestureData();
    
    EYE_STATE_TYPE CASE = selectCaseFromGesture(isLeftEyeOpen, isRightEyeOpen, lastGestureData.getIsLeftEyeOpen(), lastGestureData.getIsRightEyeOpen());

    switch(CASE){

        /* 1) ì–‘ì•ˆì„ ì§€ì†ì ìœ¼ë¡œ ëœ¬ ê²½ìš° */
        case EYE_STATE_TYPE(BOTH_OPEN_TO_BOTH_OPEN):
            accumulatedTime = std::chrono::duration_cast<std::chrono::duration<double>>(std::chrono::nanoseconds(0));
            for(std::vector<GestureData>::iterator it = this->getGestureDataBuffer().end()-1; it != this->getGestureDataBuffer().begin()-1; it--){
                if(it->getIsLeftEyeOpen() && it->getIsRightEyeOpen()){
                    accumulatedTime += it->getFrameTime(); // sec
                }else{ 
                    break;
                }
            }

            if(accumulatedTime.count() <= 0){
                // exception.
                result =  Gesture(NONE);

            }else if(this->getDoubleClickFlag()){
                // ëˆ„ì ì‹œê°„ì´ 1ì´ˆ ë¯¸ë§Œì¸ê°€?
                if(accumulatedTime.count() < 0.6){
                    // ë”ë¸” í´ë¦­ ëŒ€ê¸°
                    this->resetFlags();
                    this->setDoubleClickFlag(true);
                    result = Gesture(WAIT);
                }else{
                    // 0.6ì´ˆ ì´ìƒì´ë©´ì„œ ë”ë¸”í´ë¦­ í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ -> ë”ë¸” í´ë¦­ í”Œë˜ê·¸ ì´ˆê¸°í™”
                    this->resetFlags();
                    this->setDoubleClickFlag(false);
                    result = Gesture(NONE);
                }
            }else{
                // ë”ë¸”í´ë¦­ í”Œë˜ê·¸ê°€ ì—†ëŠ” ê²½ìš°
                //ì¢Œìš° ì„¼í„° ê°„ y í”½ì…€ ì°¨ì´ ê²€ì‚¬ -> ìŠ¤í¬ë¡¤ || í¬ì¸í„° ì´ë™ 
                if(leftEyeCenter.y > rightEyeCenter.y && (leftEyeCenter.y - rightEyeCenter.y) > ET__MIN_SCROLL_MARGIN){
                    // ê³ ê°œ ì¢Œì¸¡ ê¸°ìš¸ì„. ìƒí–¥ ìŠ¤í¬ë¡¤
                    this->resetFlags();
                    result = Gesture(SCROLL_UP);
                }else if(leftEyeCenter.y < rightEyeCenter.y && (rightEyeCenter.y - leftEyeCenter.y) > ET__MIN_SCROLL_MARGIN){
                    // ê³ ê°œ ìš°ì¸¡ ê¸°ìš¸ì„. í•˜í–¥ ìŠ¤í¬ë¡¤
                    this->resetFlags();
                    result = Gesture(SCROLL_DOWN);
                }else{
                    // í¬ì¸í„° ì´ë™
                    //// ğŸ”§êµ¬í˜„ ì˜ˆì •
                }
            }

            break;

        /* 2) ì§€ê¸ˆì€ ì–‘ì•ˆì„ ë–´ì§€ë§Œ ë°©ê¸ˆê¹Œì§€ í•œìª½ ëˆˆë§Œ ëœ¬ ê²½ìš° */
        case EYE_STATE_TYPE(SINGLE_OPEN_TO_BOTH_OPEN):
            accumulatedTime = std::chrono::duration_cast<std::chrono::duration<double>>(std::chrono::nanoseconds(0));
            for(std::vector<GestureData>::iterator it = this->getGestureDataBuffer().end()-1; it != this->getGestureDataBuffer().begin()-1; it--){
                if((lastGestureData.getIsLeftEyeOpen() == it->getIsLeftEyeOpen()) && (lastGestureData.getIsRightEyeOpen() == it->getIsRightEyeOpen())){
                    accumulatedTime += it->getFrameTime(); // sec
                }else{ 
                    break;
                }
            }
            
            if(accumulatedTime.count() <= 0){
                // exception.
                result =  Gesture(NONE);
            }else if(this->getRightClickFlag()){
                std::cout << "RIGHT CLICK FLAG ON" << std::endl;
                if(this->getDragFlag()){
                // ìš°í´ë¦­ ê²€ì‚¬ í”Œë˜ê·¸ì™€ ë“œë˜ê·¸ í”Œë˜ê·¸ê°€ ìˆëŠ” ê²½ìš° -> ë“œë¡­ ë° ë“œë˜ê·¸/ìš°í´ë¦­ í”Œë˜ê·¸ ì´ˆê¸°í™”
                    result = Gesture(DROP);
                    this->resetFlags();
                    this->setDragFlag(false);
                    this->setRightClickFlag(false);
                }else{
                // ìš°í´ë¦­ ê²€ì‚¬ í”Œë˜ê·¸ë§Œ ìˆëŠ” ê²½ìš° -> ìš°í´ë¦­ ë° ìš°í´ë¦­ í”Œë˜ê·¸ ì´ˆê¸°í™”
                   result = Gesture(RIGHT_CLICK);
                   this->resetFlags();
                    this->setRightClickFlag(false);
                }
            }else{
                // exception. ë‹¤ ì•„ë‹ˆë©´ ëˆˆì„ ì˜ëª» ì¸ì‹í•œ ê²½ìš° ë“± ì˜ˆì™¸
                result = Gesture(NONE);
            }

            break;

        /* 3) ì§€ê¸ˆì€ ì–‘ì•ˆì„ ë–³ì§€ë§Œ ë°©ê¸ˆê¹Œì§€ ë‘ ëˆˆ ëª¨ë‘ ê°ì€ ê²½ìš° */
        case EYE_STATE_TYPE(BOTH_CLOSE_TO_BOTH_OPEN):
            accumulatedTime = std::chrono::duration_cast<std::chrono::duration<double>>(std::chrono::nanoseconds(0));
            for(std::vector<GestureData>::iterator it = this->getGestureDataBuffer().end()-1; it != this->getGestureDataBuffer().begin()-1; it--){
                if(!it->getIsLeftEyeOpen() && !it->getIsRightEyeOpen()){
                    accumulatedTime += it->getFrameTime(); // sec
                }else{ 
                    break;
                }
            }
            // std::cout << "ì•ˆêµ¬ ê¹œë¹¡ì„ì— ê±¸ë¦° ëˆ„ì  ì‹œê°„ : " << accumulatedTime.count() << "ì´ˆ" << std::endl;
            if(accumulatedTime.count() <= 0){
                // exception. ì¼ë‹¨ ì¨ë†“ìŒ
                result =  Gesture(NONE);
            }else if(accumulatedTime.count() >= 0.3){
                // 0.6ì´ˆ ì´ìƒ 3ì´ˆ ë¯¸ë§Œ -> !!ìˆ˜ì • 0.3ì´ˆ ì´ìƒ. 0.2ë„ ê´œì°®ì„ë“¯
                if(accumulatedTime.count() < 3){
                    if(this->getDoubleClickFlag()){
                        result = Gesture(DOUBLE_CLICK);
                        this->setDoubleClickFlag(false);
                    }else{
                        result = Gesture(LEFT_CLICK);
                        this->setDoubleClickFlag(true);
                    }
                }else{
                // 3ì´ˆ ì´ìƒ
                    if(this->getInterfaceEnableFlag()){
                        // ì¸í„°í˜ì´ìŠ¤ í™œì„±í™”ì˜€ì„ ì‹œ
                        result = Gesture(INTERFACE_DISABLE);
                        this->setInterfaceEnableFlag(false);
                    }else{
                        // ì¸í„°í˜ì´ìŠ¤ ë¹„í™œì„±í™”ì˜€ì„ ì‹œ
                        result = Gesture(INTERFACE_ENABLE);
                        this->setInterfaceEnableFlag(true);
                    }
                }
            }else{
                // 0.6ì´ˆ ë¯¸ë§Œ -> ê·¸ëƒ¥ ëˆˆ ê¹œë¹¡ì¸ ê²ƒì´ë¯€ë¡œ ë¬´ì‹œ
                result = Gesture(NONE);
            }

            break;

        /* 4) ì§€ê¸ˆì€ í•œ ìª½ ëˆˆë§Œ ë–´ì§€ë§Œ ë°©ê¸ˆê¹Œì§€ ë‘ ëˆˆì„ ëœ¬ ê²½ìš° */
        case EYE_STATE_TYPE(BOTH_OPEN_TO_SINGLE_OPEN):
            result = Gesture(WAIT);
            
            break;

        /* 5) ì§€ê¸ˆë„ í•œ ìª½ ëˆˆë§Œ ë–³ê³  ë°©ê¸ˆë„ í•œìª½ëˆˆë§Œ ëœ¬ ê²½ìš°  */
        case EYE_STATE_TYPE(SINGLE_OPEN_TO_SINGLE_OPEN):
            accumulatedTime = std::chrono::duration_cast<std::chrono::duration<double>>(std::chrono::nanoseconds(0));
            for(std::vector<GestureData>::iterator it = this->getGestureDataBuffer().end()-1; it != this->getGestureDataBuffer().begin()-1; it--){
                if((lastGestureData.getIsLeftEyeOpen() == it->getIsLeftEyeOpen()) && (lastGestureData.getIsRightEyeOpen() == it->getIsRightEyeOpen())){
                    accumulatedTime += it->getFrameTime(); // sec
                }else{ 
                    break;
                }
            }

            if(accumulatedTime.count() <= 0){
                // exception. ì¼ë‹¨ ì¨ë†“ìŒ
                result =  Gesture(NONE);
            }else{
                 if(this->getRightClickFlag()){
                    // ìš°í´ë¦­ í”Œë˜ê·¸ì¸ ê²½ìš° 
                    if(this->getDragFlag()){
                        // ìš°í´ë¦­ì´ë©´ì„œ ë“œë˜ê·¸ì¸ ê²½ìš° == ìš°í´ë¦­ í›„ ì›€ì§ì„ì´ ì¡°ê¸ˆì´ë¼ë„ ìˆì—ˆë˜ ê²½ìš°
                        // ì•„ë˜ì™€ ë‹¬ë¦¬, ì¡°ê±´ ê²€ì‚¬ ì—†ì´, ë°”ë¡œ ìœ„ì¹˜ ì°¨ì´ ê³„ì‚° í›„ ì´ˆì  ì´ë™ 
                        result = Gesture(DRAG);
                    }else{
                        // ìš°í´ë¦­ì´ì§€ë§Œ ì•„ì§ ë“œë˜ê·¸ í”Œë˜ê·¸ëŠ” ì—†ëŠ” ê²½ìš°
                        // ì•„ë˜ì˜ ì£¼ì„ëœ ì½”ë“œ ì •ìƒ ì‘ë™ í™•ì¸ ì™„ë£Œ
                        
                        // std::cout << "ìš°í´ë¦­ ì‹œê°„ 0.3ì´ˆ ì´ìƒì´ë¼ ë“œë˜ê·¸ í”Œë˜ê·¸ tureëœ ìƒíƒœì„" << std::endl;
                        // result = Gesture(RIGHT_CLICK);
                        // this->resetFlags();
                        // this->setRightClickFlag(true);

                        if(isLeftEyeOpen && lastGestureData.getIsLeftEyeOpen()){
                            // ì™¼ìª½ ëˆˆì´ ì—´ë¦° ê²½ìš°
                            // ğŸ”§ êµ¬í˜„ í•„ìš”: ì™¼ìª½ ëˆˆì˜ ì§ì „ ìœ„ì¹˜ì™€ í˜„ì¬ ìœ„ì¹˜ ì°¨ì´ ê³„ì‚°
                                // ë§Œì•½ ìœ„ì¹˜ ì°¨ì´ê°€ 5í”½ì…€ ì´ìƒì´ë©´ -> this->setDragFlag(true); result = Gesture(DRAG); ìœ„ì¹˜ ì°¨ì´ë§Œí¼ ì´ˆì  ì´ë™
                        }else if(isRightEyeOpen && lastGestureData.getIsRightEyeOpen()){
                            // ì˜¤ë¥¸ìª½ ëˆˆì´ ì—´ë¦° ê²½ìš°
                            // ğŸ”§ êµ¬í˜„ í•„ìš”: ì˜¤ë¥¸ìª½ ëˆˆì˜ ì§ì „ ìœ„ì¹˜ì™€ í˜„ì¬ ìœ„ì¹˜ ì°¨ì´ ê³„ì‚° í›„ ì €ì¥ ë° ì´ë™
                                // ë§Œì•½ ìœ„ì¹˜ ì°¨ì´ê°€ 5í”½ì…€ ì´ìƒì´ë©´ -> this->setDragFlag(true); result = Gesture(DRAG); ìœ„ì¹˜ ì°¨ì´ë§Œí¼ ì´ˆì  ì´ë™
                        }else{
                        }
                    }
                 }else{
                    // ìš°í´ë¦­ í”Œë˜ê·¸ ì—†ëŠ” ê²½ìš°
                    if(accumulatedTime.count() < 0.3){
                        // ëˆ„ì  ì‹œê°„ 1ì´ˆ ë¯¸ë§Œ -> ë‹¨ìˆœ ëŒ€ê¸°
                        std::cout << "ì—°ì†ì ìœ¼ë¡œ í•œëˆˆë§Œ ê°ê³  ìˆìŒ!!" << std::endl;
                        result = Gesture(WAIT);
                    }else{
                        // ëˆ„ì  ì‹œê°„ 1ì´ˆ ì´ìƒ -> ìš°í´ë¦­ í”Œë˜ê·¸ ë° ëŒ€ê¸°(ëˆˆ ëœ° ë•Œ ì ìš©ì´ë¯€ë¡œ)
                        // ìš°í´ë¦­ ê²€ì‚¬ í”Œë˜ê·¸ê°€ ì—†ìœ¼ë©´ 1ì´ˆ ë¯¸ë§Œ -> ìš°í´ë¦­ ëŒ€ê¸° ì¤‘ || 1ì´ˆ ì´ìƒ -> ìš°í´ë¦­ë§Œ ëˆ„ë¥´ê³  ë“œë˜ê·¸ëŠ” ì•ˆí•œ ê²½ìš° 
                        // â­ï¸ ì´ ë¶€ë¶„ 3ì´ˆ ë¯¸ë§Œ ìœ ì§€ ë‚´ìš© ìˆ˜ì •í•¨. ë…¼ë¬¸ì— í‘œ 1ì— strike ê·¸ë ¤ë†“ìŒ
                        std::cout << "ìš°í´ë¦­ ì¤€ë¹„ ì™„ë£Œ!!! ëˆˆ ë–¼ë©´ ìš°í´ë¦­ í”Œë˜ê·¸ trueì¸ ìƒíƒœ" << std::endl;
                        result = Gesture(WAIT);
                        this->resetFlags();
                        this->setRightClickFlag(true);
                    }
                 }
            }

            break;

        /* 6) ì§€ê¸ˆì€ í•œìª½ ëˆˆë§Œ ë–´ì§€ë§Œ ë°©ê¸ˆê¹Œì§€ëŠ” ë‘ ëˆˆì„ ê°ì€ ê²½ìš°*/
        case EYE_STATE_TYPE(BOTH_CLOSE_TO_SINGLE_OPEN):
            result = Gesture(NONE);

            break;

        /* 7) ì§€ê¸ˆì€ ë‘ ëˆˆ ë‹¤ ê°ì•˜ì§€ë§Œ ë°©ê¸ˆê¹Œì§€ëŠ” ë‘ ëˆˆ ëª¨ë‘ ëœ¬ ê²½ìš° */
        case EYE_STATE_TYPE(BOTH_OPEN_TO_BOTH_CLOSE):
            result = Gesture(NONE);

            break;

        /* 8) ì§€ê¸ˆì€ ë‘ ëˆˆ ë‹¤ ê°ì•˜ì§€ë§Œ ë°©ê¸ˆê¹Œì§€ëŠ” í•œ ìª½ ëˆˆë§Œ ê°ì€ ê²½ìš° */
        case EYE_STATE_TYPE(SINGLE_OPEN_TO_BOTH_CLOSE):
            result = Gesture(NONE);

            break;
        /* 9) ì§€ê¸ˆë„ ë‘ ëˆˆ ë‹¤ ê°ì•˜ê³  ë°©ê¸ˆê¹Œì§€ë„ ë‘ ëˆˆ ëª¨ë‘ ê°ì€ ê²½ìš° */
        case EYE_STATE_TYPE(BOTH_CLOSE_TO_BOTH_CLOSE):
            result = Gesture(NONE);

            break;

        default:
            break;
    }

    // End Point Of Duration(sec).
    durationTime = std::chrono::system_clock::now() - start;

    thisGestureData = GestureData(durationTime, leftEyeCenter, rightEyeCenter, isLeftEyeOpen, isRightEyeOpen);
    
    // <will be deleted>
    // Accumulate total time.
    // this->setGestureTime(totalTime + durationTime);
    // </will be deleted>

    // Update gesture data and its buffer.
    //// ì œìŠ¤ì²˜ ë²„í¼ ì‚¬ì´ì¦ˆê°€ ìµœëŒ€ ì´ìƒì´ë©´ pop í•˜ëŠ” ì—°ì‚° í•„ìš”
    if(this->getGestureDataBuffer().size() >= ET__MAX_BUFFER_LENGTH){
        this->popFromGestureDataBuffer();
    }
    this->pushToGestureDataBuffer(thisGestureData);
    this->setLastGestureData(thisGestureData);

    return result;
}
// duration.count()
// this->setGestureTime(durationTime);

// ë‘ëˆˆì„ ë‹¤ ëœ¬ ê²½ìš°
    // focusPoint = cv::Point(
    //     ((rightEyeCenter.x - leftEyeCenter.x)/2 + leftEyeCenter.x),
    //     (leftEyeCenter.y < rightEyeCenter.y ? ((leftEyeCenter.y - rightEyeCenter.y)/2 + leftEyeCenter.y) : ((rightEyeCenter.y - leftEyeCenter.y)/2 + rightEyeCenter.y))
    // );
// í•œìª½ ëˆˆë§Œ ëœ¬ ê²½ìš°
    // ì§ì „ ëˆˆì˜ ì •ë³´ì™€ ê°ì€ ìª½ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ + ì¼ì¹˜í•œë‹¤ë©´ ì´ë™ ê±°ë¦¬ ê³„ì‚°í•´ì„œ focusPointì— ë°˜ì˜
// ë‘ëˆˆ ë‹¤ ê°ì€ ê²½ìš°
    // ì§ì „ ëˆˆì˜ focusPoint ì •ë³´ ê·¸ëŒ€ë¡œ ì‚¬ìš©

// focusPoint = this->getLastGesture().getCursor();
EYE_STATE_TYPE EyeTracker::selectCaseFromGesture(bool isLeftEyeOpen, bool isRightEyeOpen, bool isLastLeftEyeOpen, bool isLastRightEyeOpen){
    if(isLeftEyeOpen && isRightEyeOpen){
        if(isLastLeftEyeOpen && isLastRightEyeOpen){
            return EYE_STATE_TYPE(BOTH_OPEN_TO_BOTH_OPEN);
        }else if(isLastLeftEyeOpen || isLastRightEyeOpen){
            return EYE_STATE_TYPE(SINGLE_OPEN_TO_BOTH_OPEN);
        }else{
            return EYE_STATE_TYPE(BOTH_CLOSE_TO_BOTH_OPEN);
        }
    }else if(isLeftEyeOpen || isRightEyeOpen){
        if(isLastLeftEyeOpen && isLastRightEyeOpen){
            return EYE_STATE_TYPE(BOTH_OPEN_TO_SINGLE_OPEN);
        }else if(isLastLeftEyeOpen || isLastRightEyeOpen){
            return EYE_STATE_TYPE(SINGLE_OPEN_TO_SINGLE_OPEN);
        }else{
            return EYE_STATE_TYPE(BOTH_CLOSE_TO_SINGLE_OPEN);
        }
    }else{
        if(isLastLeftEyeOpen && isLastRightEyeOpen){
            return EYE_STATE_TYPE(BOTH_OPEN_TO_BOTH_CLOSE);
        }else if(isLastLeftEyeOpen || isLastRightEyeOpen){
            return EYE_STATE_TYPE(SINGLE_OPEN_TO_BOTH_CLOSE);
        }else{
            return EYE_STATE_TYPE(BOTH_CLOSE_TO_BOTH_CLOSE);
        }
    }
}